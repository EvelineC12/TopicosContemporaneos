{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvelineC12/TopicosContemporaneos/blob/main/Primeiro_projeto_final_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Wyed2iy4phk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN3as6FJvL-5"
      },
      "source": [
        "**Primeiro Projeto Final**\n",
        "\n",
        "**Disciplina Tópicos Contemporâneos**\n",
        "\n",
        "**Aluna:**\n",
        "\n",
        "**Eveline Cavalcanti Feliciano Pontual** (ecfp@cesar.school)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuP565ezupWl"
      },
      "source": [
        "**Objetivo do Projeto:** Fine-Tuning de uma CNN para Classificação\n",
        "\n",
        "Um dataset de sua escolha deverá ser coletado e preparado para realizar o fine-tuning de uma CNN. O projeto será avaliado nos seguintes aspectos: Construção do Dataset, Data Augmentation, Uso de Modelos Pré-Treinados, Construção do Modelo Classificador, Congelamento de Camadas, Treinamento e Curvas de Desempenho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jm1mhFjUi8A"
      },
      "source": [
        "# **1. Baixar o dataset criado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y99wy4pTHPcP",
        "outputId": "a08a3795-bdfb-4498-f04d-797266775866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1noJAmWiPSPtAG-yE32bVqXXvHqtCAetC\n",
            "To: /content/passaros.zip\n",
            "100% 10.2M/10.2M [00:00<00:00, 43.9MB/s]\n",
            "Archive:  passaros.zip\n",
            "   creating: data/passaros/\n",
            "   creating: data/passaros/train/\n",
            "   creating: data/passaros/train/beijaflor/\n",
            "  inflating: data/passaros/train/beijaflor/10002.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10016.png  \n",
            "  inflating: data/passaros/train/beijaflor/10017.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10025.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10026.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10027.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10029.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10032.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10033.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10034.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10035.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10036.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10037.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10038.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10039.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10040.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10041.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10042.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10043.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10044.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10046.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10047.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10048.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10049.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10050.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10051.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10052.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10053.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10054.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10055.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10056.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10057.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10058.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10059.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10060.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10061.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10062.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10063.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10064.png  \n",
            "  inflating: data/passaros/train/beijaflor/10065.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10066.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10068.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10069.webp  \n",
            "  inflating: data/passaros/train/beijaflor/10070.jpeg  \n",
            "  inflating: data/passaros/train/beijaflor/10071.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10072.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10073.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10074.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10075.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10076.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10077.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10078.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10079.jpg  \n",
            "  inflating: data/passaros/train/beijaflor/10080.webp  \n",
            "   creating: data/passaros/train/falcao/\n",
            "  inflating: data/passaros/train/falcao/01.jpg  \n",
            "  inflating: data/passaros/train/falcao/02.jpg  \n",
            "  inflating: data/passaros/train/falcao/03.jpg  \n",
            "  inflating: data/passaros/train/falcao/04.jpg  \n",
            "  inflating: data/passaros/train/falcao/05.jpg  \n",
            "  inflating: data/passaros/train/falcao/06.jpg  \n",
            "   creating: data/passaros/val/\n",
            "   creating: data/passaros/val/beijaflor/\n",
            "  inflating: data/passaros/val/beijaflor/10001.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10003.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10004.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10006.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10008.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10009.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10010.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10011.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10012.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10013.png  \n",
            "  inflating: data/passaros/val/beijaflor/10014.jpeg  \n",
            "  inflating: data/passaros/val/beijaflor/10015.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10018.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10019.jpeg  \n",
            "  inflating: data/passaros/val/beijaflor/10020.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10021.jpeg  \n",
            "  inflating: data/passaros/val/beijaflor/10022.jpg  \n",
            "  inflating: data/passaros/val/beijaflor/10024.webp  \n",
            "   creating: data/passaros/val/falcao/\n",
            "  inflating: data/passaros/val/falcao/07.jpg  \n",
            "  inflating: data/passaros/val/falcao/08.jpg  \n"
          ]
        }
      ],
      "source": [
        "# Instalar a ferramenta gdown\n",
        "!pip install gdown\n",
        "\n",
        "# Baixar o arquivo usando gdown\n",
        "!gdown \"https://drive.google.com/uc?id=1noJAmWiPSPtAG-yE32bVqXXvHqtCAetC\"\n",
        "\n",
        "# Descompactar o arquivo\n",
        "!unzip passaros.zip -d data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9qEfsgFK580R"
      },
      "outputs": [],
      "source": [
        "data_dir = \"data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuqER_EpHJpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Des6mq6uHr2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5uLgr5xrwIL"
      },
      "source": [
        "O dataset deste trabalho tem criação autoral. Imagens de pássaros da espécie beija-flor foram extraídas do Google Imagens através da ferramenta ImageAssistant Batch Image. Há aproximadamente 60 imagens para base de treino e 20 imagens para a base de validação.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he-srCy-UwA1"
      },
      "source": [
        "# **2. Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ooRjnSbb6Ak_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from PIL import Image\n",
        "from torchvision.models import resnet50, ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J6ePv016Hfn",
        "outputId": "efa93b19-224e-47ba-fb45-af940d448f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqYnkzIhWmb_"
      },
      "source": [
        "# **3. Funções para treinar, testar e avaliar modelo de aprendizado profundo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QrLIcqqe6JHB"
      },
      "outputs": [],
      "source": [
        "def train_model(model, trainloader, valloader, criterion, optimizer, device, num_epochs=5):\n",
        "    history = {\n",
        "        'train_losses': [],\n",
        "        'val_losses': [],\n",
        "        'train_accuracies': [],\n",
        "        'val_accuracies': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Treinamento\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, data in tqdm(enumerate(trainloader, 0), total=len(trainloader)):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(trainloader)\n",
        "        train_acc = 100 * correct / total\n",
        "        history['train_losses'].append(train_loss)\n",
        "        history['train_accuracies'].append(train_acc)\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.3f}, Train Accuracy: {train_acc:.2f}%')\n",
        "\n",
        "        # Validação\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_running_loss / len(valloader)\n",
        "        val_acc = 100 * correct / total\n",
        "        history['val_losses'].append(val_loss)\n",
        "        history['val_accuracies'].append(val_acc)\n",
        "        print(f'Epoch {epoch+1}, Val Loss: {val_loss:.3f}, Val Accuracy: {val_acc:.2f}%')\n",
        "\n",
        "    print('Treinamento concluído')\n",
        "    return history\n",
        "\n",
        "\n",
        "def test_model(model, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Acurácia da rede na base de teste: {100 * correct / total:.2f}%')\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    ax1.plot(history['train_losses'], label='Train')\n",
        "    ax1.plot(history['val_losses'], label='Validation')\n",
        "    ax1.set_title('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(history['train_accuracies'], label='Train')\n",
        "    ax2.plot(history['val_accuracies'], label='Validation')\n",
        "    ax2.set_title('Accuracy')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_images(images, titles=None, cols=5):\n",
        "    rows = (len(images) + cols - 1) // cols\n",
        "    plt.figure(figsize=(cols * 3, rows * 3))\n",
        "    for i, img in enumerate(images):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(img)\n",
        "        if titles is not None:\n",
        "            plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzksehmxXlWn"
      },
      "source": [
        "# **4. Transformações de algumas imagens**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "m8OgXiyZ7CbV",
        "outputId": "fbc2f3d4-3e62-4063-9f87-fee33becb673"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-fa8378361d0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#imagens da base de treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexample_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexample_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexample_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"
          ]
        }
      ],
      "source": [
        "example_dir = os.path.join(data_dir, 'train')\n",
        "#imagens da base de treino\n",
        "example_set = datasets.ImageFolder(example_dir, transform=None)\n",
        "example_images = [example_set[i][0] for i in random.sample(range(len(example_set)), 5)]\n",
        "\n",
        "# Mostrando imagens originais\n",
        "print(\"Imagens Originais\")\n",
        "show_images(example_images)\n",
        "\n",
        "# Exemplo de RandomResizedCrop -corte aleatório e redimensionamento\n",
        "cropped_images = [transforms.RandomResizedCrop(224)(img) for img in example_images]\n",
        "print(\"Após RandomResizedCrop\")\n",
        "show_images(cropped_images)\n",
        "\n",
        "# Exemplo de RandomHorizontalFlip - Inverte aleatoriamente as imagens horizontalmente.\n",
        "flipped_images = [transforms.RandomHorizontalFlip()(img) for img in cropped_images]\n",
        "print(\"Após RandomHorizontalFlip\")\n",
        "show_images(flipped_images)\n",
        "\n",
        "# Exemplo de RandomRotation - Aplica rotações aleatórias em uma imagem\n",
        "rotated_images = [transforms.RandomRotation(15)(img) for img in example_images]\n",
        "print(\"Após RandomRotation\")\n",
        "show_images(rotated_images)\n",
        "\n",
        "# Exemplo de RandomAffine - Aplica uma transformação afim aleatória em uma imagem\n",
        "affined_images = [transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1))(img) for img in example_images]\n",
        "print(\"Após RandomAffine\")\n",
        "show_images(affined_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpfmGKzDZGZI"
      },
      "source": [
        "# **5. Datasets (treino e validação) com e sem aumentos (augmentations) de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zM1ZoRpTb2Wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "bd8fb6d6-2031-47e1-bb80-2a35e2e69500"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e047876d7d8f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Aplicações das Transformações nas bases e treino e validação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_set_no_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_no_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtrain_set_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_no_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"
          ]
        }
      ],
      "source": [
        "# Transformações com aumentos de dados (augmentations)\n",
        "transform_aug = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),  # corte aleatório e redimensionamento\n",
        "    transforms.RandomHorizontalFlip(),  # Inverter aleatoriamente as imagens horizontalmente\n",
        "    transforms.RandomRotation(15),      # Aplica rotações aleatórias em uma imagem\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.2, hue=0.05), # altera o brilho, contraste, saturação e matiz das imagens.\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), shear=10), #  aplica transformações geométricas em uma imagem, como rotação, translação e cisalhamento (shear)\n",
        "    transforms.RandomVerticalFlip(),  # inverte aleatoriamente uma imagem na direção vertical (de cima para baixo)\n",
        "    transforms.RandomInvert(0.5),  #inverte as cores de uma imagem aleatoriamente, aplicando uma inversão de tonalidade de cor\n",
        "    transforms.ToTensor(),  #apesar de ser etapa comum de pré-processamento e não aumentar a diversidade dos dados, foi deixado aqui devido a sua necessidade para aplicações e comparações\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # #apesar de ser etapa comum de pré-processamento e não aumentar a diversidade dos dados, foi deixado aqui devido a sua necessidade para aplicações e comparações\n",
        "])\n",
        "\n",
        "# Transformações sem aumentos de dados (augmentations) - técnicas de pré-processamento\n",
        "transform_no_aug = transforms.Compose([\n",
        "    transforms.Resize(224),  # redimensiona imagem para uma altura (ou largura) específica\n",
        "    transforms.CenterCrop(224), # corta (crop) uma imagem ao redor do centro, mantendo uma região quadrada de tamanho especificado\n",
        "    transforms.ToTensor(), #converte uma imagem do tipo PIL ou NumPy ndarray para um tensor PyTorch - etapa comum de pré-processamento, não aumenta a diversidade dos dados\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #usado para normalizar as imagens\n",
        "])\n",
        "\n",
        "# Aplicações das Transformações nas bases e treino e validação\n",
        "train_set_no_aug = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_no_aug)\n",
        "train_set_aug = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_aug)\n",
        "val_set = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_no_aug)\n",
        "\n",
        "train_loader_no_aug = DataLoader(train_set_no_aug, batch_size=32, shuffle=True) #carrega os dados de treinamento em batches (lotes) durante o treinamento do modelo ( sem data augmentation)\n",
        "train_loader_aug = DataLoader(train_set_aug, batch_size=32, shuffle=True)       #carrega os dados de treinamento em batches (lotes) durante o treinamento do modelo ( com data augmentation)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)                   #carregar os dados de validação em batches (lotes) durante o treinamento do modelo (sem data augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcLKcQw2ae9f"
      },
      "source": [
        "# **6.Rede neural convolucional simples (CNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnrJw8oeNT6e"
      },
      "source": [
        "# **6.1 Primeira Tentativa - sem dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdL88a8acQUU",
        "outputId": "4b99bf11-6eb0-4312-927e-c6c186ed99f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "# primeira tentativa de função\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=0) #camadas convolucionais são boas para extrair características hierárquicas de imagens\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=0)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 2 * 2, 128) # As camadas lineares (fc1, fc2, fc3) são responsáveis pela classificação da rede.\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2, stride=2, padding=0) #relu-função de ativação não linear, aplicada após as camadas convolucionais e lineares\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2, stride=2, padding=0) # F.max_pool2d após cada camada convolucional reduz a dimensionalidade espacial das imagens\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=2, stride=2, padding=0)\n",
        "        x = x.view(-1, 64 * 2 * 2) # achata a saída das camadas convolucionais para que possa ser passada para as camadas lineares.\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "# Modelo\n",
        "model = CNN(num_classes=4).to(device)\n",
        "\n",
        "#Exemplo de entrada\n",
        "x = torch.randn(1, 3, 224, 224).to(device)\n",
        "print(model(x).shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_CsexQccFYf"
      },
      "source": [
        "**6.1.1 Aplicação do CNN -dataset sem aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gM_v_1ElcXYW",
        "outputId": "134f882e-5d81-4231-e9a2-742746e063ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_no_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-40b89a50c831>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_no_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_no_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory_no_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_no_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_no_aug' is not defined"
          ]
        }
      ],
      "source": [
        "model_no_aug = CNN(num_classes=4).to(device)\n",
        "\n",
        "criterion_no_aug = nn.CrossEntropyLoss() # Função de perda para múltiplas classes\n",
        "optimizer_no_aug = optim.Adam(model_no_aug.parameters(), lr=0.001)\n",
        "\n",
        "history_no_aug = train_model(model_no_aug, train_loader_no_aug, val_loader, criterion_no_aug, optimizer_no_aug, device, num_epochs=20)\n",
        "\n",
        "plot_history(history_no_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiO-Yfr8TCac"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMcgjKgBcvUm"
      },
      "source": [
        "**6.1.2 Aplicação do CNN no dataset com aumentos de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "meitBobQbx0d",
        "outputId": "ebbdeecd-8c77-4c6b-e3dc-f201dc1a705d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-3e0f8c59af30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_aug' is not defined"
          ]
        }
      ],
      "source": [
        "model_aug = CNN(num_classes=4).to(device)\n",
        "\n",
        "criterion_aug = nn.CrossEntropyLoss()\n",
        "optimizer_aug = optim.Adam(model_aug.parameters(), lr=0.001)\n",
        "\n",
        "history_aug = train_model(model_aug, train_loader_aug, val_loader, criterion_aug, optimizer_aug, device, num_epochs=20)\n",
        "\n",
        "plot_history(history_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFMCE_UPW_4F"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqUP1sbINtyS"
      },
      "source": [
        "# **6.2 Segunda Tentativa - Com Dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DOUphq3NO9h",
        "outputId": "d0c0d095-21e2-4ab4-fa50-03201220176a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "class CNN2(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=0)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 2 * 2, 128)\n",
        "        self.dropout1 = nn.Dropout(0.4)  # Adicionando dropout\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2, stride=2, padding=0)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2, stride=2, padding=0)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=2, stride=2, padding=0)\n",
        "        x = x.view(-1, 64 * 2 * 2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)  # Aplicando dropout\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Inicialização do modelo\n",
        "model2 = CNN2(num_classes=4).to(device)\n",
        "\n",
        "# Exemplo de entrada\n",
        "x = torch.randn(1, 3, 224, 224).to(device)\n",
        "print(model2(x).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elhOMJsZPJcv"
      },
      "source": [
        "**6.2.1 Aplicação do CNN -dataset sem aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "c0N5DiqzPRx0",
        "outputId": "813e517b-ca8d-4b4e-bb46-2bf4b4dc6cd6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_no_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-bca169ac18f2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_no_aug2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_no_aug2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory_no_aug2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_no_aug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_no_aug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_no_aug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_no_aug2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_no_aug' is not defined"
          ]
        }
      ],
      "source": [
        "model_no_aug2 = CNN2(num_classes=4).to(device)\n",
        "\n",
        "criterion_no_aug2 = nn.CrossEntropyLoss() # Função de perda para múltiplas classes\n",
        "optimizer_no_aug2 = optim.Adam(model_no_aug2.parameters(), lr=0.001)\n",
        "\n",
        "history_no_aug2 = train_model(model_no_aug2, train_loader_no_aug, val_loader, criterion_no_aug2, optimizer_no_aug2, device, num_epochs=30)\n",
        "\n",
        "plot_history(history_no_aug2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTwQAPGhlAef"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R589ECNKP9v0"
      },
      "source": [
        "**6.2.2 Aplicação do CNN -com dropout e dataset com aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_fs452oHQgtH",
        "outputId": "866bd177-8fa1-4299-ca0c-e4d621f4fc2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-4878495813d8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_aug2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_aug2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory_aug2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_aug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_aug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_aug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_aug2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_aug' is not defined"
          ]
        }
      ],
      "source": [
        "model_aug2 = CNN2(num_classes=4).to(device)\n",
        "\n",
        "criterion_aug2 = nn.CrossEntropyLoss()\n",
        "optimizer_aug2 = optim.Adam(model_aug2.parameters(), lr=0.001)\n",
        "\n",
        "history_aug2 = train_model(model_aug2, train_loader_aug, val_loader, criterion_aug2, optimizer_aug2, device, num_epochs=30)\n",
        "\n",
        "plot_history(history_aug2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTW6cg-wrmLQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5x1HG2eeuzz"
      },
      "source": [
        "# **7. Aplicação de Modelos Pré-Treinados**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCmpsJshnAND"
      },
      "source": [
        "**7.1 Definição das transformações com e sem data augmentation e datasets (treino e validação)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "UXvbwq9dnFO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3ddfb15d-9cc0-45e6-bd41-768a8844a4e0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-22bb8afc9a53>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set_no_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_no_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_set_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_no_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader_no_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"
          ]
        }
      ],
      "source": [
        "train_set_no_aug = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_no_aug)\n",
        "train_set_aug = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_aug)\n",
        "val_set = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_no_aug)\n",
        "\n",
        "train_loader_no_aug = DataLoader(train_set_no_aug, batch_size=32, shuffle=True)\n",
        "train_loader_aug = DataLoader(train_set_aug, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3zxnm-QnMRw"
      },
      "source": [
        "**7.2 Definição da função de treinamento e avaliação**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dzMm61XMnPIT"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return epoch_loss, accuracy\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return epoch_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a5fqz_InbXC"
      },
      "source": [
        "**7.3. Carregamento dos Modelos com Pesos Pré-Treinados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "iQ39NRuPncjS",
        "outputId": "a6194afc-2474-4d2f-8743-456e88a29d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 99.7MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 71.8MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_set_no_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-44cb04266487>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Modificar a camada final para o número de classes do seu dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_no_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ou train_set_aug.classes, depende do seu dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#o correto é 4, pois são 4 tipos de frutas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_no_aug' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Carregar ResNet50 com pesos pré-treinados\n",
        "resnet_model_v1 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "resnet_model_v2 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "\n",
        "# Carregar VGG16 com pesos pré-treinados\n",
        "vgg_model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modificar a camada final para o número de classes do seu dataset\n",
        "num_classes = len(train_set_no_aug.classes)  # ou train_set_aug.classes, depende do seu dataset\n",
        "print(num_classes) #o correto é 4, pois são 4 tipos de frutas\n",
        "\n",
        "resnet_model_v1.fc = nn.Linear(resnet_model_v1.fc.in_features, num_classes)\n",
        "resnet_model_v2.fc = nn.Linear(resnet_model_v2.fc.in_features, num_classes)\n",
        "vgg_model.classifier[6] = nn.Linear(vgg_model.classifier[6].in_features, num_classes)\n",
        "\n",
        "# Transferir os modelos para o dispositivo (GPU ou CPU)\n",
        "resnet_model_v1 = resnet_model_v1.to(device)\n",
        "resnet_model_v2 = resnet_model_v2.to(device)\n",
        "vgg_model = vgg_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paiaZ13F-zwP",
        "outputId": "49b009db-1621-4eaa-b294-279b863bf400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(resnet_model_v1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrB86dlN_EKo",
        "outputId": "7754410b-09b8-420d-e4c4-c3be3bd74e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(resnet_model_v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3MaV0os_No3",
        "outputId": "8dbef0b5-f099-4bc7-f9ab-08deeb7f7ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(vgg_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpPGsxybnohD"
      },
      "source": [
        "**7.4 Definição do otimizador e critério de perda**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "EgU4GZS4nwmg"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_resnet_v1 = optim.Adam(resnet_model_v1.parameters(), lr=0.001)\n",
        "optimizer_resnet_v2 = optim.Adam(resnet_model_v2.parameters(), lr=0.001)\n",
        "optimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WHBFSt2n5ct"
      },
      "source": [
        "# **7.5 Treinamento e Avaliação do Modelo Pré-Treinado**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz2EyaR2gHWO"
      },
      "source": [
        "# **7.5.1 ResNet50 (versão 1)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLF-ukaA4Hj"
      },
      "source": [
        "**7.5.1.1 Aplicado na Base de Treino sem aumento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ot7NoZVWxBg4",
        "outputId": "d62d427e-6fc0-4e99-eaa0-d88146a40c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_no_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e34389fc042c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_no_aug' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do ResNet50 (versão 1) #é aplicado na base de treino sem aumento\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(resnet_model_v1, train_loader_no_aug, criterion, optimizer_resnet_v1, device)\n",
        "    val_loss, val_acc = evaluate(resnet_model_v1, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "d-uOPfDgxTNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "1b96696b-b72f-4536-bcbd-afa5a0eae881"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b6f7d4ceda35>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "CdEg4wVjpkFR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFp7IRkqBTTh"
      },
      "source": [
        "**7.5.1.2 Aplicado na Base de Treino com aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "o_07W1zcB4Dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ad83c4e8-973a-4c82-9c25-af8891c393e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-49dde6267a86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_aug' is not defined"
          ]
        }
      ],
      "source": [
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses2 = []\n",
        "train_accuracies2= []\n",
        "val_losses2 = []\n",
        "val_accuracies2 = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do ResNet50 (versão 1) #é aplicado na base de treino sem aumento\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(resnet_model_v1, train_loader_aug, criterion, optimizer_resnet_v1, device)\n",
        "    val_loss, val_acc = evaluate(resnet_model_v1, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses2.append(train_loss)\n",
        "    train_accuracies2.append(train_acc)\n",
        "    val_losses2.append(val_loss)\n",
        "    val_accuracies2.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "w3dpN-BfEOKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "06cb0f56-fd51-4d8f-8b2e-9e70fc00a533"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-b2886c4c7a41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAH/CAYAAABpfcWfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHUZJREFUeJzt3X9s1/WdwPFXKfZbzWxlx1F+XB2nO+c2JziQrjpiXHoj0bDjj8s4XYAjTs+NM47mboI/6Jwb5ZwakokjMj2X3DzYGfWWQeq53sji5EIGNHEnahw6uGWtcDtahlsr7ef+WOzWAY5vbeFFeTyS7x99+/58P+/vO92e/Xx/8K0oiqIIAOCUG3eqFwAA/JYoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEmVH+Yc//GHMnz8/pk6dGhUVFfH000//0WO2bt0aH/3oR6NUKsX73//+eOyxx4axVAAY28qO8uHDh2PGjBmxbt26E5r/2muvxbXXXhtXX311dHR0xBe+8IX47Gc/G88880zZiwWAsazi3XwhRUVFRTz11FOxYMGC48657bbbYvPmzfGTn/xkcOxv/uZv4uDBg9HW1jbcUwPAmDN+tE+wbdu2aGpqGjI2b968+MIXvnDcY3p7e6O3t3fw54GBgfjlL38Zf/InfxIVFRWjtVQAOCFFUcShQ4di6tSpMW7cyL09a9Sj3NnZGXV1dUPG6urqoqenJ37961/H2WeffdQxra2tcffdd4/20gDgXdm3b1/82Z/92Yjd36hHeThWrlwZzc3Ngz93d3fH+eefH/v27YuamppTuDIAiOjp6Yn6+vo499xzR/R+Rz3KkydPjq6uriFjXV1dUVNTc8yr5IiIUqkUpVLpqPGamhpRBiCNkX5JddQ/p9zY2Bjt7e1Dxp599tlobGwc7VMDwGml7Cj/6le/io6Ojujo6IiI337kqaOjI/bu3RsRv33qefHixYPzb7755tizZ0988YtfjJdeeikeeuih+M53vhPLly8fmUcAAGNE2VH+8Y9/HJdddllcdtllERHR3Nwcl112WaxatSoiIn7xi18MBjoi4s///M9j8+bN8eyzz8aMGTPi/vvvj29+85sxb968EXoIADA2vKvPKZ8sPT09UVtbG93d3V5TBuCUG60u+bevASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgiWFFed26dTF9+vSorq6OhoaG2L59+zvOX7t2bXzgAx+Is88+O+rr62P58uXxm9/8ZlgLBoCxquwob9q0KZqbm6OlpSV27twZM2bMiHnz5sUbb7xxzPmPP/54rFixIlpaWmL37t3xyCOPxKZNm+L2229/14sHgLGk7Cg/8MADceONN8bSpUvjQx/6UKxfvz7OOeecePTRR485//nnn48rr7wyrr/++pg+fXp88pOfjOuuu+6PXl0DwJmmrCj39fXFjh07oqmp6Xd3MG5cNDU1xbZt2455zBVXXBE7duwYjPCePXtiy5Ytcc0117yLZQPA2DO+nMkHDhyI/v7+qKurGzJeV1cXL7300jGPuf766+PAgQPx8Y9/PIqiiCNHjsTNN9/8jk9f9/b2Rm9v7+DPPT095SwTAE5Lo/7u661bt8bq1avjoYceip07d8aTTz4Zmzdvjnvuuee4x7S2tkZtbe3grb6+frSXCQCnXEVRFMWJTu7r64tzzjknnnjiiViwYMHg+JIlS+LgwYPx7//+70cdM3fu3PjYxz4WX/va1wbH/uVf/iVuuumm+NWvfhXjxh39d8GxrpTr6+uju7s7ampqTnS5ADAqenp6ora2dsS7VNaVclVVVcyaNSva29sHxwYGBqK9vT0aGxuPecybb755VHgrKysjIuJ4fw+USqWoqakZcgOAsa6s15QjIpqbm2PJkiUxe/bsmDNnTqxduzYOHz4cS5cujYiIxYsXx7Rp06K1tTUiIubPnx8PPPBAXHbZZdHQ0BCvvvpq3HXXXTF//vzBOAMAw4jywoULY//+/bFq1aro7OyMmTNnRltb2+Cbv/bu3TvkyvjOO++MioqKuPPOO+PnP/95/Omf/mnMnz8/vvrVr47cowCAMaCs15RPldF67h4AhiPFa8oAwOgRZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASGJYUV63bl1Mnz49qquro6GhIbZv3/6O8w8ePBjLli2LKVOmRKlUiosuuii2bNkyrAUDwFg1vtwDNm3aFM3NzbF+/fpoaGiItWvXxrx58+Lll1+OSZMmHTW/r68v/vIv/zImTZoUTzzxREybNi1+9rOfxXnnnTcS6weAMaOiKIqinAMaGhri8ssvjwcffDAiIgYGBqK+vj5uueWWWLFixVHz169fH1/72tfipZdeirPOOmtYi+zp6Yna2tro7u6OmpqaYd0HAIyU0epSWU9f9/X1xY4dO6Kpqel3dzBuXDQ1NcW2bduOecx3v/vdaGxsjGXLlkVdXV1ccsklsXr16ujv7z/ueXp7e6Onp2fIDQDGurKifODAgejv74+6uroh43V1ddHZ2XnMY/bs2RNPPPFE9Pf3x5YtW+Kuu+6K+++/P77yla8c9zytra1RW1s7eKuvry9nmQBwWhr1d18PDAzEpEmT4uGHH45Zs2bFwoUL44477oj169cf95iVK1dGd3f34G3fvn2jvUwAOOXKeqPXxIkTo7KyMrq6uoaMd3V1xeTJk495zJQpU+Kss86KysrKwbEPfvCD0dnZGX19fVFVVXXUMaVSKUqlUjlLA4DTXllXylVVVTFr1qxob28fHBsYGIj29vZobGw85jFXXnllvPrqqzEwMDA49sorr8SUKVOOGWQAOFOV/fR1c3NzbNiwIb71rW/F7t2743Of+1wcPnw4li5dGhERixcvjpUrVw7O/9znPhe//OUv49Zbb41XXnklNm/eHKtXr45ly5aN3KMAgDGg7M8pL1y4MPbv3x+rVq2Kzs7OmDlzZrS1tQ2++Wvv3r0xbtzvWl9fXx/PPPNMLF++PC699NKYNm1a3HrrrXHbbbeN3KMAgDGg7M8pnwo+pwxAJik+pwwAjB5RBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASCJYUV53bp1MX369Kiuro6GhobYvn37CR23cePGqKioiAULFgzntAAwppUd5U2bNkVzc3O0tLTEzp07Y8aMGTFv3rx444033vG4119/Pf7hH/4h5s6dO+zFAsBYVnaUH3jggbjxxhtj6dKl8aEPfSjWr18f55xzTjz66KPHPaa/vz8+85nPxN133x0XXHDBu1owAIxVZUW5r68vduzYEU1NTb+7g3HjoqmpKbZt23bc47785S/HpEmT4oYbbjih8/T29kZPT8+QGwCMdWVF+cCBA9Hf3x91dXVDxuvq6qKzs/OYxzz33HPxyCOPxIYNG074PK2trVFbWzt4q6+vL2eZAHBaGtV3Xx86dCgWLVoUGzZsiIkTJ57wcStXrozu7u7B2759+0ZxlQCQw/hyJk+cODEqKyujq6tryHhXV1dMnjz5qPk//elP4/XXX4/58+cPjg0MDPz2xOPHx8svvxwXXnjhUceVSqUolUrlLA0ATntlXSlXVVXFrFmzor29fXBsYGAg2tvbo7Gx8aj5F198cbzwwgvR0dExePvUpz4VV199dXR0dHhaGgB+T1lXyhERzc3NsWTJkpg9e3bMmTMn1q5dG4cPH46lS5dGRMTixYtj2rRp0draGtXV1XHJJZcMOf68886LiDhqHADOdGVHeeHChbF///5YtWpVdHZ2xsyZM6OtrW3wzV979+6NceP8Q2EAUK6KoiiKU72IP6anpydqa2uju7s7ampqTvVyADjDjVaXXNICQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASQwryuvWrYvp06dHdXV1NDQ0xPbt2487d8OGDTF37tyYMGFCTJgwIZqamt5xPgCcqcqO8qZNm6K5uTlaWlpi586dMWPGjJg3b1688cYbx5y/devWuO666+IHP/hBbNu2Lerr6+OTn/xk/PznP3/XiweAsaSiKIqinAMaGhri8ssvjwcffDAiIgYGBqK+vj5uueWWWLFixR89vr+/PyZMmBAPPvhgLF68+ITO2dPTE7W1tdHd3R01NTXlLBcARtxodamsK+W+vr7YsWNHNDU1/e4Oxo2Lpqam2LZt2wndx5tvvhlvvfVWvPe97z3unN7e3ujp6RlyA4CxrqwoHzhwIPr7+6Ourm7IeF1dXXR2dp7Qfdx2220xderUIWH/Q62trVFbWzt4q6+vL2eZAHBaOqnvvl6zZk1s3Lgxnnrqqaiurj7uvJUrV0Z3d/fgbd++fSdxlQBwaowvZ/LEiROjsrIyurq6hox3dXXF5MmT3/HY++67L9asWRPf//7349JLL33HuaVSKUqlUjlLA4DTXllXylVVVTFr1qxob28fHBsYGIj29vZobGw87nH33ntv3HPPPdHW1hazZ88e/moBYAwr60o5IqK5uTmWLFkSs2fPjjlz5sTatWvj8OHDsXTp0oiIWLx4cUybNi1aW1sjIuKf/umfYtWqVfH444/H9OnTB197fs973hPvec97RvChAMDprewoL1y4MPbv3x+rVq2Kzs7OmDlzZrS1tQ2++Wvv3r0xbtzvLsC/8Y1vRF9fX/z1X//1kPtpaWmJL33pS+9u9QAwhpT9OeVTweeUAcgkxeeUAYDRI8oAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJDGsKK9bty6mT58e1dXV0dDQENu3b3/H+f/2b/8WF198cVRXV8dHPvKR2LJly7AWCwBjWdlR3rRpUzQ3N0dLS0vs3LkzZsyYEfPmzYs33njjmPOff/75uO666+KGG26IXbt2xYIFC2LBggXxk5/85F0vHgDGkoqiKIpyDmhoaIjLL788HnzwwYiIGBgYiPr6+rjllltixYoVR81fuHBhHD58OL73ve8Njn3sYx+LmTNnxvr160/onD09PVFbWxvd3d1RU1NTznIBYMSNVpfGlzO5r68vduzYEStXrhwcGzduXDQ1NcW2bduOecy2bduiubl5yNi8efPi6aefPu55ent7o7e3d/Dn7u7uiPjtJgDAqfZ2j8q8rv2jyorygQMHor+/P+rq6oaM19XVxUsvvXTMYzo7O485v7Oz87jnaW1tjbvvvvuo8fr6+nKWCwCj6n//93+jtrZ2xO6vrCifLCtXrhxydX3w4MF43/veF3v37h3RB3+m6unpifr6+ti3b5+XA0aIPR1Z9nPk2dOR1d3dHeeff368973vHdH7LSvKEydOjMrKyujq6hoy3tXVFZMnTz7mMZMnTy5rfkREqVSKUql01Hhtba1fphFUU1NjP0eYPR1Z9nPk2dORNW7cyH6yuKx7q6qqilmzZkV7e/vg2MDAQLS3t0djY+Mxj2lsbBwyPyLi2WefPe58ADhTlf30dXNzcyxZsiRmz54dc+bMibVr18bhw4dj6dKlERGxePHimDZtWrS2tkZExK233hpXXXVV3H///XHttdfGxo0b48c//nE8/PDDI/tIAOA0V3aUFy5cGPv3749Vq1ZFZ2dnzJw5M9ra2gbfzLV3794hl/NXXHFFPP7443HnnXfG7bffHn/xF38RTz/9dFxyySUnfM5SqRQtLS3HfEqb8tnPkWdPR5b9HHn2dGSN1n6W/TllAGB0+LevASAJUQaAJEQZAJIQZQBIIk2UfR3kyCpnPzds2BBz586NCRMmxIQJE6KpqemP7v+ZqNzf0bdt3LgxKioqYsGCBaO7wNNMuft58ODBWLZsWUyZMiVKpVJcdNFF/nf/B8rd07Vr18YHPvCBOPvss6O+vj6WL18ev/nNb07SanP74Q9/GPPnz4+pU6dGRUXFO35fw9u2bt0aH/3oR6NUKsX73//+eOyxx8o/cZHAxo0bi6qqquLRRx8t/vu//7u48cYbi/POO6/o6uo65vwf/ehHRWVlZXHvvfcWL774YnHnnXcWZ511VvHCCy+c5JXnVO5+Xn/99cW6deuKXbt2Fbt37y7+9m//tqitrS3+53/+5ySvPK9y9/Rtr732WjFt2rRi7ty5xV/91V+dnMWeBsrdz97e3mL27NnFNddcUzz33HPFa6+9VmzdurXo6Og4ySvPq9w9/fa3v12USqXi29/+dvHaa68VzzzzTDFlypRi+fLlJ3nlOW3ZsqW44447iieffLKIiOKpp556x/l79uwpzjnnnKK5ubl48cUXi69//etFZWVl0dbWVtZ5U0R5zpw5xbJlywZ/7u/vL6ZOnVq0trYec/6nP/3p4tprrx0y1tDQUPzd3/3dqK7zdFHufv6hI0eOFOeee27xrW99a7SWeNoZzp4eOXKkuOKKK4pvfvObxZIlS0T595S7n9/4xjeKCy64oOjr6ztZSzztlLuny5YtKz7xiU8MGWtubi6uvPLKUV3n6ehEovzFL36x+PCHPzxkbOHChcW8efPKOtcpf/r67a+DbGpqGhw7ka+D/P35Eb/9OsjjzT+TDGc//9Cbb74Zb7311oj/Q+unq+Hu6Ze//OWYNGlS3HDDDSdjmaeN4eznd7/73WhsbIxly5ZFXV1dXHLJJbF69ero7+8/WctObTh7esUVV8SOHTsGn+Les2dPbNmyJa655pqTsuaxZqS6dMq/JepkfR3kmWI4+/mHbrvttpg6depRv2BnquHs6XPPPRePPPJIdHR0nIQVnl6Gs5979uyJ//zP/4zPfOYzsWXLlnj11Vfj85//fLz11lvR0tJyMpad2nD29Prrr48DBw7Exz/+8SiKIo4cORI333xz3H777SdjyWPO8brU09MTv/71r+Pss88+ofs55VfK5LJmzZrYuHFjPPXUU1FdXX2ql3NaOnToUCxatCg2bNgQEydOPNXLGRMGBgZi0qRJ8fDDD8esWbNi4cKFcccdd8T69etP9dJOW1u3bo3Vq1fHQw89FDt37ownn3wyNm/eHPfcc8+pXtoZ7ZRfKZ+sr4M8UwxnP9923333xZo1a+L73/9+XHrppaO5zNNKuXv605/+NF5//fWYP3/+4NjAwEBERIwfPz5efvnluPDCC0d30YkN53d0ypQpcdZZZ0VlZeXg2Ac/+MHo7OyMvr6+qKqqGtU1ZzecPb3rrrti0aJF8dnPfjYiIj7ykY/E4cOH46abboo77rhjxL+ScKw7XpdqampO+Co5IsGVsq+DHFnD2c+IiHvvvTfuueeeaGtri9mzZ5+MpZ42yt3Tiy++OF544YXo6OgYvH3qU5+Kq6++Ojo6OqK+vv5kLj+d4fyOXnnllfHqq68O/nETEfHKK6/ElClTzvggRwxvT998882jwvv2Hz2Fr0Qo24h1qbz3oI2OjRs3FqVSqXjssceKF198sbjpppuK8847r+js7CyKoigWLVpUrFixYnD+j370o2L8+PHFfffdV+zevbtoaWnxkajfU+5+rlmzpqiqqiqeeOKJ4he/+MXg7dChQ6fqIaRT7p7+Ie++Hqrc/dy7d29x7rnnFn//939fvPzyy8X3vve9YtKkScVXvvKVU/UQ0il3T1taWopzzz23+Nd//ddiz549xX/8x38UF154YfHpT3/6VD2EVA4dOlTs2rWr2LVrVxERxQMPPFDs2rWr+NnPflYURVGsWLGiWLRo0eD8tz8S9Y//+I/F7t27i3Xr1p2+H4kqiqL4+te/Xpx//vlFVVVVMWfOnOK//uu/Bv/bVVddVSxZsmTI/O985zvFRRddVFRVVRUf/vCHi82bN5/kFedWzn6+733vKyLiqFtLS8vJX3hi5f6O/j5RPlq5+/n8888XDQ0NRalUKi644ILiq1/9anHkyJGTvOrcytnTt956q/jSl75UXHjhhUV1dXVRX19ffP7zny/+7//+7+QvPKEf/OAHx/z/xbf3cMmSJcVVV1111DEzZ84sqqqqigsuuKD453/+57LP66sbASCJU/6aMgDwW6IMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJDE/wMGwDMBT94guAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses2, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses2, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies2, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies2, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "05IyWvMSvSr6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tXwhGDLhH33"
      },
      "source": [
        "# **7.5.2 ResNet50 (versão 2)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz52HY6NDX4K"
      },
      "source": [
        "**7.5.2.1 Aplicado na Base de Treino sem aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "RMO7D-j6h0Io",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "62689089-f8af-4c74-a912-e96849c6bb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_no_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e0be47f83810>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_no_aug' is not defined"
          ]
        }
      ],
      "source": [
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses3 = []\n",
        "train_accuracies3 = []\n",
        "val_losses3 = []\n",
        "val_accuracies3 = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do ResNet50 (versão 2)\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(resnet_model_v2, train_loader_no_aug, criterion, optimizer_resnet_v2, device)\n",
        "    val_loss, val_acc = evaluate(resnet_model_v2, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses3.append(train_loss)\n",
        "    train_accuracies3.append(train_acc)\n",
        "    val_losses3.append(val_loss)\n",
        "    val_accuracies3.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "5eTT8SLch-IX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "dae72e30-6a1a-4745-94bc-a3c456e8d66c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-3ad8da529aae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses3, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses3, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies3, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies3, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LaYtrGmg4K0z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS0DYfexDzB_"
      },
      "source": [
        "**7.5.2.1 Aplicado na Base de Treino com aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "OvOGzEYODzVB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "5f729e1c-17b9-451e-8627-27ec43c968ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-180527b7b643>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_aug' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses4 = []\n",
        "train_accuracies4 = []\n",
        "val_losses4 = []\n",
        "val_accuracies4 = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do ResNet50 (versão 2)\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(resnet_model_v2, train_loader_aug, criterion, optimizer_resnet_v2, device)\n",
        "    val_loss, val_acc = evaluate(resnet_model_v2, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses4.append(train_loss)\n",
        "    train_accuracies4.append(train_acc)\n",
        "    val_losses4.append(val_loss)\n",
        "    val_accuracies4.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "hYqNcbqsFY-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "cc3a6a4f-755d-4f8a-9c12-31cf8b943476"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-65ac9d97aa1e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAH/CAYAAABpfcWfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHUZJREFUeJzt3X9s1/WdwPFXKfZbzWxlx1F+XB2nO+c2JziQrjpiXHoj0bDjj8s4XYAjTs+NM47mboI/6Jwb5ZwakokjMj2X3DzYGfWWQeq53sji5EIGNHEnahw6uGWtcDtahlsr7ef+WOzWAY5vbeFFeTyS7x99+/58P+/vO92e/Xx/8K0oiqIIAOCUG3eqFwAA/JYoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEmVH+Yc//GHMnz8/pk6dGhUVFfH000//0WO2bt0aH/3oR6NUKsX73//+eOyxx4axVAAY28qO8uHDh2PGjBmxbt26E5r/2muvxbXXXhtXX311dHR0xBe+8IX47Gc/G88880zZiwWAsazi3XwhRUVFRTz11FOxYMGC48657bbbYvPmzfGTn/xkcOxv/uZv4uDBg9HW1jbcUwPAmDN+tE+wbdu2aGpqGjI2b968+MIXvnDcY3p7e6O3t3fw54GBgfjlL38Zf/InfxIVFRWjtVQAOCFFUcShQ4di6tSpMW7cyL09a9Sj3NnZGXV1dUPG6urqoqenJ37961/H2WeffdQxra2tcffdd4/20gDgXdm3b1/82Z/92Yjd36hHeThWrlwZzc3Ngz93d3fH+eefH/v27YuamppTuDIAiOjp6Yn6+vo499xzR/R+Rz3KkydPjq6uriFjXV1dUVNTc8yr5IiIUqkUpVLpqPGamhpRBiCNkX5JddQ/p9zY2Bjt7e1Dxp599tlobGwc7VMDwGml7Cj/6le/io6Ojujo6IiI337kqaOjI/bu3RsRv33qefHixYPzb7755tizZ0988YtfjJdeeikeeuih+M53vhPLly8fmUcAAGNE2VH+8Y9/HJdddllcdtllERHR3Nwcl112WaxatSoiIn7xi18MBjoi4s///M9j8+bN8eyzz8aMGTPi/vvvj29+85sxb968EXoIADA2vKvPKZ8sPT09UVtbG93d3V5TBuCUG60u+bevASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgiWFFed26dTF9+vSorq6OhoaG2L59+zvOX7t2bXzgAx+Is88+O+rr62P58uXxm9/8ZlgLBoCxquwob9q0KZqbm6OlpSV27twZM2bMiHnz5sUbb7xxzPmPP/54rFixIlpaWmL37t3xyCOPxKZNm+L2229/14sHgLGk7Cg/8MADceONN8bSpUvjQx/6UKxfvz7OOeecePTRR485//nnn48rr7wyrr/++pg+fXp88pOfjOuuu+6PXl0DwJmmrCj39fXFjh07oqmp6Xd3MG5cNDU1xbZt2455zBVXXBE7duwYjPCePXtiy5Ytcc0117yLZQPA2DO+nMkHDhyI/v7+qKurGzJeV1cXL7300jGPuf766+PAgQPx8Y9/PIqiiCNHjsTNN9/8jk9f9/b2Rm9v7+DPPT095SwTAE5Lo/7u661bt8bq1avjoYceip07d8aTTz4Zmzdvjnvuuee4x7S2tkZtbe3grb6+frSXCQCnXEVRFMWJTu7r64tzzjknnnjiiViwYMHg+JIlS+LgwYPx7//+70cdM3fu3PjYxz4WX/va1wbH/uVf/iVuuumm+NWvfhXjxh39d8GxrpTr6+uju7s7ampqTnS5ADAqenp6ora2dsS7VNaVclVVVcyaNSva29sHxwYGBqK9vT0aGxuPecybb755VHgrKysjIuJ4fw+USqWoqakZcgOAsa6s15QjIpqbm2PJkiUxe/bsmDNnTqxduzYOHz4cS5cujYiIxYsXx7Rp06K1tTUiIubPnx8PPPBAXHbZZdHQ0BCvvvpq3HXXXTF//vzBOAMAw4jywoULY//+/bFq1aro7OyMmTNnRltb2+Cbv/bu3TvkyvjOO++MioqKuPPOO+PnP/95/Omf/mnMnz8/vvrVr47cowCAMaCs15RPldF67h4AhiPFa8oAwOgRZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASGJYUV63bl1Mnz49qquro6GhIbZv3/6O8w8ePBjLli2LKVOmRKlUiosuuii2bNkyrAUDwFg1vtwDNm3aFM3NzbF+/fpoaGiItWvXxrx58+Lll1+OSZMmHTW/r68v/vIv/zImTZoUTzzxREybNi1+9rOfxXnnnTcS6weAMaOiKIqinAMaGhri8ssvjwcffDAiIgYGBqK+vj5uueWWWLFixVHz169fH1/72tfipZdeirPOOmtYi+zp6Yna2tro7u6OmpqaYd0HAIyU0epSWU9f9/X1xY4dO6Kpqel3dzBuXDQ1NcW2bduOecx3v/vdaGxsjGXLlkVdXV1ccsklsXr16ujv7z/ueXp7e6Onp2fIDQDGurKifODAgejv74+6uroh43V1ddHZ2XnMY/bs2RNPPPFE9Pf3x5YtW+Kuu+6K+++/P77yla8c9zytra1RW1s7eKuvry9nmQBwWhr1d18PDAzEpEmT4uGHH45Zs2bFwoUL44477oj169cf95iVK1dGd3f34G3fvn2jvUwAOOXKeqPXxIkTo7KyMrq6uoaMd3V1xeTJk495zJQpU+Kss86KysrKwbEPfvCD0dnZGX19fVFVVXXUMaVSKUqlUjlLA4DTXllXylVVVTFr1qxob28fHBsYGIj29vZobGw85jFXXnllvPrqqzEwMDA49sorr8SUKVOOGWQAOFOV/fR1c3NzbNiwIb71rW/F7t2743Of+1wcPnw4li5dGhERixcvjpUrVw7O/9znPhe//OUv49Zbb41XXnklNm/eHKtXr45ly5aN3KMAgDGg7M8pL1y4MPbv3x+rVq2Kzs7OmDlzZrS1tQ2++Wvv3r0xbtzvWl9fXx/PPPNMLF++PC699NKYNm1a3HrrrXHbbbeN3KMAgDGg7M8pnwo+pwxAJik+pwwAjB5RBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASAJUQaAJEQZAJIQZQBIQpQBIAlRBoAkRBkAkhBlAEhClAEgCVEGgCREGQCSEGUASEKUASCJYUV53bp1MX369Kiuro6GhobYvn37CR23cePGqKioiAULFgzntAAwppUd5U2bNkVzc3O0tLTEzp07Y8aMGTFv3rx444033vG4119/Pf7hH/4h5s6dO+zFAsBYVnaUH3jggbjxxhtj6dKl8aEPfSjWr18f55xzTjz66KPHPaa/vz8+85nPxN133x0XXHDBu1owAIxVZUW5r68vduzYEU1NTb+7g3HjoqmpKbZt23bc47785S/HpEmT4oYbbjih8/T29kZPT8+QGwCMdWVF+cCBA9Hf3x91dXVDxuvq6qKzs/OYxzz33HPxyCOPxIYNG074PK2trVFbWzt4q6+vL2eZAHBaGtV3Xx86dCgWLVoUGzZsiIkTJ57wcStXrozu7u7B2759+0ZxlQCQw/hyJk+cODEqKyujq6tryHhXV1dMnjz5qPk//elP4/XXX4/58+cPjg0MDPz2xOPHx8svvxwXXnjhUceVSqUolUrlLA0ATntlXSlXVVXFrFmzor29fXBsYGAg2tvbo7Gx8aj5F198cbzwwgvR0dExePvUpz4VV199dXR0dHhaGgB+T1lXyhERzc3NsWTJkpg9e3bMmTMn1q5dG4cPH46lS5dGRMTixYtj2rRp0draGtXV1XHJJZcMOf68886LiDhqHADOdGVHeeHChbF///5YtWpVdHZ2xsyZM6OtrW3wzV979+6NceP8Q2EAUK6KoiiKU72IP6anpydqa2uju7s7ampqTvVyADjDjVaXXNICQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASQwryuvWrYvp06dHdXV1NDQ0xPbt2487d8OGDTF37tyYMGFCTJgwIZqamt5xPgCcqcqO8qZNm6K5uTlaWlpi586dMWPGjJg3b1688cYbx5y/devWuO666+IHP/hBbNu2Lerr6+OTn/xk/PznP3/XiweAsaSiKIqinAMaGhri8ssvjwcffDAiIgYGBqK+vj5uueWWWLFixR89vr+/PyZMmBAPPvhgLF68+ITO2dPTE7W1tdHd3R01NTXlLBcARtxodamsK+W+vr7YsWNHNDU1/e4Oxo2Lpqam2LZt2wndx5tvvhlvvfVWvPe97z3unN7e3ujp6RlyA4CxrqwoHzhwIPr7+6Ourm7IeF1dXXR2dp7Qfdx2220xderUIWH/Q62trVFbWzt4q6+vL2eZAHBaOqnvvl6zZk1s3Lgxnnrqqaiurj7uvJUrV0Z3d/fgbd++fSdxlQBwaowvZ/LEiROjsrIyurq6hox3dXXF5MmT3/HY++67L9asWRPf//7349JLL33HuaVSKUqlUjlLA4DTXllXylVVVTFr1qxob28fHBsYGIj29vZobGw87nH33ntv3HPPPdHW1hazZ88e/moBYAwr60o5IqK5uTmWLFkSs2fPjjlz5sTatWvj8OHDsXTp0oiIWLx4cUybNi1aW1sjIuKf/umfYtWqVfH444/H9OnTB197fs973hPvec97RvChAMDprewoL1y4MPbv3x+rVq2Kzs7OmDlzZrS1tQ2++Wvv3r0xbtzvLsC/8Y1vRF9fX/z1X//1kPtpaWmJL33pS+9u9QAwhpT9OeVTweeUAcgkxeeUAYDRI8oAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJCEKANAEqIMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJDGsKK9bty6mT58e1dXV0dDQENu3b3/H+f/2b/8WF198cVRXV8dHPvKR2LJly7AWCwBjWdlR3rRpUzQ3N0dLS0vs3LkzZsyYEfPmzYs33njjmPOff/75uO666+KGG26IXbt2xYIFC2LBggXxk5/85F0vHgDGkoqiKIpyDmhoaIjLL788HnzwwYiIGBgYiPr6+rjllltixYoVR81fuHBhHD58OL73ve8Njn3sYx+LmTNnxvr160/onD09PVFbWxvd3d1RU1NTznIBYMSNVpfGlzO5r68vduzYEStXrhwcGzduXDQ1NcW2bduOecy2bduiubl5yNi8efPi6aefPu55ent7o7e3d/Dn7u7uiPjtJgDAqfZ2j8q8rv2jyorygQMHor+/P+rq6oaM19XVxUsvvXTMYzo7O485v7Oz87jnaW1tjbvvvvuo8fr6+nKWCwCj6n//93+jtrZ2xO6vrCifLCtXrhxydX3w4MF43/veF3v37h3RB3+m6unpifr6+ti3b5+XA0aIPR1Z9nPk2dOR1d3dHeeff368973vHdH7LSvKEydOjMrKyujq6hoy3tXVFZMnTz7mMZMnTy5rfkREqVSKUql01Hhtba1fphFUU1NjP0eYPR1Z9nPk2dORNW7cyH6yuKx7q6qqilmzZkV7e/vg2MDAQLS3t0djY+Mxj2lsbBwyPyLi2WefPe58ADhTlf30dXNzcyxZsiRmz54dc+bMibVr18bhw4dj6dKlERGxePHimDZtWrS2tkZExK233hpXXXVV3H///XHttdfGxo0b48c//nE8/PDDI/tIAOA0V3aUFy5cGPv3749Vq1ZFZ2dnzJw5M9ra2gbfzLV3794hl/NXXHFFPP7443HnnXfG7bffHn/xF38RTz/9dFxyySUnfM5SqRQtLS3HfEqb8tnPkWdPR5b9HHn2dGSN1n6W/TllAGB0+LevASAJUQaAJEQZAJIQZQBIIk2UfR3kyCpnPzds2BBz586NCRMmxIQJE6KpqemP7v+ZqNzf0bdt3LgxKioqYsGCBaO7wNNMuft58ODBWLZsWUyZMiVKpVJcdNFF/nf/B8rd07Vr18YHPvCBOPvss6O+vj6WL18ev/nNb07SanP74Q9/GPPnz4+pU6dGRUXFO35fw9u2bt0aH/3oR6NUKsX73//+eOyxx8o/cZHAxo0bi6qqquLRRx8t/vu//7u48cYbi/POO6/o6uo65vwf/ehHRWVlZXHvvfcWL774YnHnnXcWZ511VvHCCy+c5JXnVO5+Xn/99cW6deuKXbt2Fbt37y7+9m//tqitrS3+53/+5ySvPK9y9/Rtr732WjFt2rRi7ty5xV/91V+dnMWeBsrdz97e3mL27NnFNddcUzz33HPFa6+9VmzdurXo6Og4ySvPq9w9/fa3v12USqXi29/+dvHaa68VzzzzTDFlypRi+fLlJ3nlOW3ZsqW44447iieffLKIiOKpp556x/l79uwpzjnnnKK5ubl48cUXi69//etFZWVl0dbWVtZ5U0R5zpw5xbJlywZ/7u/vL6ZOnVq0trYec/6nP/3p4tprrx0y1tDQUPzd3/3dqK7zdFHufv6hI0eOFOeee27xrW99a7SWeNoZzp4eOXKkuOKKK4pvfvObxZIlS0T595S7n9/4xjeKCy64oOjr6ztZSzztlLuny5YtKz7xiU8MGWtubi6uvPLKUV3n6ehEovzFL36x+PCHPzxkbOHChcW8efPKOtcpf/r67a+DbGpqGhw7ka+D/P35Eb/9OsjjzT+TDGc//9Cbb74Zb7311oj/Q+unq+Hu6Ze//OWYNGlS3HDDDSdjmaeN4eznd7/73WhsbIxly5ZFXV1dXHLJJbF69ero7+8/WctObTh7esUVV8SOHTsGn+Les2dPbNmyJa655pqTsuaxZqS6dMq/JepkfR3kmWI4+/mHbrvttpg6depRv2BnquHs6XPPPRePPPJIdHR0nIQVnl6Gs5979uyJ//zP/4zPfOYzsWXLlnj11Vfj85//fLz11lvR0tJyMpad2nD29Prrr48DBw7Exz/+8SiKIo4cORI333xz3H777SdjyWPO8brU09MTv/71r+Pss88+ofs55VfK5LJmzZrYuHFjPPXUU1FdXX2ql3NaOnToUCxatCg2bNgQEydOPNXLGRMGBgZi0qRJ8fDDD8esWbNi4cKFcccdd8T69etP9dJOW1u3bo3Vq1fHQw89FDt37ownn3wyNm/eHPfcc8+pXtoZ7ZRfKZ+sr4M8UwxnP9923333xZo1a+L73/9+XHrppaO5zNNKuXv605/+NF5//fWYP3/+4NjAwEBERIwfPz5efvnluPDCC0d30YkN53d0ypQpcdZZZ0VlZeXg2Ac/+MHo7OyMvr6+qKqqGtU1ZzecPb3rrrti0aJF8dnPfjYiIj7ykY/E4cOH46abboo77rhjxL+ScKw7XpdqampO+Co5IsGVsq+DHFnD2c+IiHvvvTfuueeeaGtri9mzZ5+MpZ42yt3Tiy++OF544YXo6OgYvH3qU5+Kq6++Ojo6OqK+vv5kLj+d4fyOXnnllfHqq68O/nETEfHKK6/ElClTzvggRwxvT998882jwvv2Hz2Fr0Qo24h1qbz3oI2OjRs3FqVSqXjssceKF198sbjpppuK8847r+js7CyKoigWLVpUrFixYnD+j370o2L8+PHFfffdV+zevbtoaWnxkajfU+5+rlmzpqiqqiqeeOKJ4he/+MXg7dChQ6fqIaRT7p7+Ie++Hqrc/dy7d29x7rnnFn//939fvPzyy8X3vve9YtKkScVXvvKVU/UQ0il3T1taWopzzz23+Nd//ddiz549xX/8x38UF154YfHpT3/6VD2EVA4dOlTs2rWr2LVrVxERxQMPPFDs2rWr+NnPflYURVGsWLGiWLRo0eD8tz8S9Y//+I/F7t27i3Xr1p2+H4kqiqL4+te/Xpx//vlFVVVVMWfOnOK//uu/Bv/bVVddVSxZsmTI/O985zvFRRddVFRVVRUf/vCHi82bN5/kFedWzn6+733vKyLiqFtLS8vJX3hi5f6O/j5RPlq5+/n8888XDQ0NRalUKi644ILiq1/9anHkyJGTvOrcytnTt956q/jSl75UXHjhhUV1dXVRX19ffP7zny/+7//+7+QvPKEf/OAHx/z/xbf3cMmSJcVVV1111DEzZ84sqqqqigsuuKD453/+57LP66sbASCJU/6aMgDwW6IMAEmIMgAkIcoAkIQoA0ASogwASYgyACQhygCQhCgDQBKiDABJiDIAJCHKAJDE/wMGwDMBT94guAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses4, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses4, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies4, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies4, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Axxtdj7I-2V7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPm3FmbNhcck"
      },
      "source": [
        "# **7.5.3 VGG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPmBTv0lGGDU"
      },
      "source": [
        "**7.5.3.1 Aplicado na Base de Treino sem aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ZNJZhNGO4TDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "3a25fcdf-dc48-4ffd-8b91-b0296cf0cf80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_no_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-07dfe390e3ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_no_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_no_aug' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses5 = []\n",
        "train_accuracies5 = []\n",
        "val_losses5 = []\n",
        "val_accuracies5 = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do VGG\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(vgg_model, train_loader_no_aug, criterion, optimizer_vgg, device)\n",
        "    val_loss, val_acc = evaluate(vgg_model, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses5.append(train_loss)\n",
        "    train_accuracies5.append(train_acc)\n",
        "    val_losses5.append(val_loss)\n",
        "    val_accuracies5.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "itmve2UO4sLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "cb902d3e-ab7b-498f-8ad0-8532c6619de1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-e4643881741e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses5, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses5, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies5, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies5, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZDC6pdA1IhG2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTujOJ6BGNjc"
      },
      "source": [
        "**7.5.3.2 Aplicado na Base de Treino com aumento de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "hkbcwqXHGqve",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "7c20113d-aae9-45cf-ce57-1821ec9db14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-1bd12abf0c05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_aug' is not defined"
          ]
        }
      ],
      "source": [
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses6 = []\n",
        "train_accuracies6 = []\n",
        "val_losses6 = []\n",
        "val_accuracies6 = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do VGG\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(vgg_model, train_loader_aug, criterion, optimizer_vgg, device)\n",
        "    val_loss, val_acc = evaluate(vgg_model, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses6.append(train_loss)\n",
        "    train_accuracies6.append(train_acc)\n",
        "    val_losses6.append(val_loss)\n",
        "    val_accuracies6.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "FYUgVu1YG8rK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "3a598e56-3719-4c8e-daba-27e19086b1bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-babca9447a22>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses6, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses6, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies6, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies6, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S6hsTmYkVvmP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRrBU_jkoeog"
      },
      "source": [
        "# **8. Congelamento das Camadas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "3_kteOs1ua3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "49804250-670b-4a2a-e3f1-0b59f5e5bcb8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_set_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-8ec58cff13e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Modificar a camada final para o número de classes do dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set_aug' is not defined"
          ]
        }
      ],
      "source": [
        "# Carregar ResNet50 com pesos pré-treinados\n",
        "resnet_model_v1 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "for param in resnet_model_v1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modificar a camada final para o número de classes do dataset\n",
        "num_classes = len(train_set_aug.classes)\n",
        "\n",
        "resnet_model_v1.fc = nn.Linear(resnet_model_v1.fc.in_features, num_classes)\n",
        "\n",
        "# Transferir os modelos para o dispositivo (GPU ou CPU)\n",
        "resnet_model_v1 = resnet_model_v1.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_resnet_v1 = optim.Adam(resnet_model_v1.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "qrIlOUovvMid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "99af0daf-38f4-401e-c6b4-9f266c265fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader_aug' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-0238017a06f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model_v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader_aug' is not defined"
          ]
        }
      ],
      "source": [
        "# Listas para armazenar as métricas de cada época\n",
        "train_losses0 = []\n",
        "train_accuracies0 = []\n",
        "val_losses0 = []\n",
        "val_accuracies0 = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Treinamento e Avaliação do ResNet50 (versão 1)\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_loss, train_acc = train(resnet_model_v1, train_loader_aug, criterion, optimizer_resnet_v1, device)\n",
        "    val_loss, val_acc = evaluate(resnet_model_v1, val_loader, criterion, device)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    train_losses0.append(train_loss)\n",
        "    train_accuracies0.append(train_acc)\n",
        "    val_losses0.append(val_loss)\n",
        "    val_accuracies0.append(val_acc)\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotando os gráficos\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses0, label='Train Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses0, label='Val Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies0, label='Train Accuracy', color='blue', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies0, label='Val Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ylV0mPE3aE7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b980d564-6e83-43e4-9b47-de9f7dfca369"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-24f8fd5b71e6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gráfico de Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k4td-pR_kHeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Conclusões**"
      ],
      "metadata": {
        "id": "yZv7pABaYabD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coleta de dados, mesmo que simples, é de grande importância para o desenvolvimento de modelos de CNN de classificação, independente se pré-treinados ou não. É importante ter atenção na representatividade desses dados, tanto no âmbito da qualidade como quantidade.\n",
        "\n"
      ],
      "metadata": {
        "id": "jkvCLVH6OYRu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}